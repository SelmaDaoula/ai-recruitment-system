"""
Fine-tuning spaCy NER pour d√©tecter les comp√©tences dans les CVs
"""

import spacy
from spacy.training import Example
from spacy.util import minibatch, compounding
import random
import json
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')


class SpacyNERTrainer:
    """
    Entra√Æneur de mod√®le spaCy NER custom
    """
    
    def __init__(self, base_model: str = "fr_core_news_md"):
        """
        Initialise avec un mod√®le de base
        
        Args:
            base_model: Mod√®le spaCy de base √† fine-tuner
        """
        print(f"\nüì• Chargement du mod√®le de base : {base_model}")
        
        try:
            self.nlp = spacy.load(base_model)
            print(f"‚úÖ Mod√®le {base_model} charg√©")
        except:
            print(f"‚ö†Ô∏è  Mod√®le {base_model} introuvable, t√©l√©chargement...")
            from subprocess import run
            run(f"python -m spacy download {base_model}".split())
            self.nlp = spacy.load(base_model)
        
        # Ajouter le NER si absent
        if "ner" not in self.nlp.pipe_names:
            ner = self.nlp.add_pipe("ner", last=True)
        else:
            ner = self.nlp.get_pipe("ner")
        
        self.ner = ner
        
        # Ajouter notre label custom
        self.ner.add_label("SKILL")
        
        print(f"‚úÖ Label 'SKILL' ajout√© au NER")
    
    def load_data(self, train_file: str, test_file: str):
        """
        Charge les donn√©es d'entra√Ænement et de test
        
        Args:
            train_file: Fichier JSON avec donn√©es d'entra√Ænement
            test_file: Fichier JSON avec donn√©es de test
        """
        print(f"\nüìÇ Chargement des donn√©es...")
        
        with open(train_file, 'r', encoding='utf-8') as f:
            self.train_data = json.load(f)
        
        with open(test_file, 'r', encoding='utf-8') as f:
            self.test_data = json.load(f)
        
        print(f"‚úÖ Train : {len(self.train_data)} exemples")
        print(f"‚úÖ Test : {len(self.test_data)} exemples")
    
    def prepare_examples(self, data):
        """
        Convertit les donn√©es au format spaCy Example
        """
        examples = []
        
        for text, annotations in data:
            doc = self.nlp.make_doc(text)
            example = Example.from_dict(doc, annotations)
            examples.append(example)
        
        return examples
    
    def train(self, n_iter: int = 30, dropout: float = 0.2):
        """
        Entra√Æne le mod√®le
        
        Args:
            n_iter: Nombre d'it√©rations
            dropout: Taux de dropout pour r√©gularisation
        """
        print(f"\nüîÑ D√©but de l'entra√Ænement...")
        print(f"   It√©rations : {n_iter}")
        print(f"   Dropout : {dropout}")
        
        # Pr√©parer les exemples
        train_examples = self.prepare_examples(self.train_data)
        
        # D√©sactiver les autres pipes pendant l'entra√Ænement
        other_pipes = [pipe for pipe in self.nlp.pipe_names if pipe != "ner"]
        
        with self.nlp.disable_pipes(*other_pipes):
            # Optimiseur
            optimizer = self.nlp.resume_training()
            
            # Boucle d'entra√Ænement
            for iteration in range(n_iter):
                random.shuffle(train_examples)
                losses = {}
                
                # Mini-batches avec taille croissante
                batches = minibatch(train_examples, size=compounding(4.0, 32.0, 1.001))
                
                for batch in batches:
                    self.nlp.update(
                        batch,
                        drop=dropout,
                        losses=losses,
                        sgd=optimizer
                    )
                
                # Afficher la progression
                if (iteration + 1) % 5 == 0 or iteration == 0:
                    print(f"   It√©ration {iteration + 1}/{n_iter} - Loss: {losses['ner']:.4f}")
        
        print(f"\n‚úÖ Entra√Ænement termin√© !")
    
    def evaluate(self):
        """
        √âvalue le mod√®le sur le test set
        """
        print(f"\nüìä √âvaluation sur le test set...")
        
        test_examples = self.prepare_examples(self.test_data)
        
        # Calculer les m√©triques
        scores = self.nlp.evaluate(test_examples)
        
        print(f"\nüìà R√âSULTATS:")
        print(f"   Precision : {scores['ents_p']:.2%}")
        print(f"   Recall    : {scores['ents_r']:.2%}")
        print(f"   F1-Score  : {scores['ents_f']:.2%}")
        
        return scores
    
    def test_predictions(self, n_samples: int = 5):
        """
        Teste le mod√®le sur quelques exemples
        """
        print(f"\nüß™ TEST SUR {n_samples} EXEMPLES:")
        print("="*60)
        
        for i, (text, annotations) in enumerate(random.sample(self.test_data, n_samples)):
            doc = self.nlp(text)
            
            print(f"\nüìÑ Exemple {i+1}:")
            print(f"Texte : {text[:100]}...")
            
            # Entit√©s pr√©dites
            print(f"\nü§ñ Pr√©dictions du mod√®le :")
            if doc.ents:
                for ent in doc.ents:
                    print(f"   ‚Ä¢ {ent.text} [{ent.label_}]")
            else:
                print(f"   (Aucune comp√©tence d√©tect√©e)")
            
            # Entit√©s r√©elles
            print(f"\n‚úÖ Annotations r√©elles :")
            for start, end, label in annotations["entities"]:
                skill = text[start:end]
                print(f"   ‚Ä¢ {skill} [{label}]")
            
            print("-"*60)
    
    def save_model(self, output_dir: str = "models/skill_ner"):
        """
        Sauvegarde le mod√®le entra√Æn√©
        """
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        self.nlp.to_disk(output_path)
        
        print(f"\nüíæ Mod√®le sauvegard√© : {output_path}")
        
        return output_path
    
    def compare_before_after(self, text: str):
        """
        Compare les pr√©dictions avant et apr√®s fine-tuning
        """
        print(f"\nüîç COMPARAISON AVANT/APR√àS FINE-TUNING")
        print("="*60)
        print(f"Texte : {text}")
        print("-"*60)
        
        # Charger le mod√®le de base non fine-tun√©
        base_nlp = spacy.load("fr_core_news_md")
        
        print(f"\n‚ùå AVANT (mod√®le de base) :")
        base_doc = base_nlp(text)
        if base_doc.ents:
            for ent in base_doc.ents:
                print(f"   ‚Ä¢ {ent.text} [{ent.label_}]")
        else:
            print(f"   (Aucune entit√© d√©tect√©e)")
        
        print(f"\n‚úÖ APR√àS (mod√®le fine-tun√©) :")
        tuned_doc = self.nlp(text)
        if tuned_doc.ents:
            for ent in tuned_doc.ents:
                print(f"   ‚Ä¢ {ent.text} [{ent.label_}]")
        else:
            print(f"   (Aucune comp√©tence d√©tect√©e)")
        
        print("="*60)


# ============ Script principal ============

if __name__ == "__main__":
    import sys
    
    print("\n" + "="*60)
    print("üéì FINE-TUNING spaCy NER POUR D√âTECTION DE COMP√âTENCES")
    print("="*60)
    
    # V√©rifier si on utilise V2
    use_v2 = "--v2" in sys.argv or "--data-version" in sys.argv
    
    if use_v2:
        print("\nüì¶ Utilisation du dataset V2 (Qualit√© am√©lior√©e)")
        train_file = "data/training/train_data_v2.json"
        test_file = "data/training/test_data_v2.json"
        output_dir = "models/skill_ner_v2"
    else:
        print("\nüì¶ Utilisation du dataset V1")
        train_file = "data/training/train_data.json"
        test_file = "data/training/test_data.json"
        output_dir = "models/skill_ner_v1"
    
    # Cr√©er le trainer
    trainer = SpacyNERTrainer(base_model="fr_core_news_md")
    
    # Charger les donn√©es
    trainer.load_data(train_file=train_file, test_file=test_file)
    
    # Entra√Æner
    trainer.train(n_iter=30, dropout=0.2)
    
    # √âvaluer
    scores = trainer.evaluate()
    
    # Tester sur quelques exemples
    trainer.test_predictions(n_samples=3)
    
    # Sauvegarder
    model_path = trainer.save_model(output_dir=output_dir)
    
    # Comparaison avant/apr√®s
    test_text = "J'ai 5 ans d'exp√©rience en Python et Django. Ma√Ætrise de PostgreSQL et Docker."
    trainer.compare_before_after(test_text)
    
    print("\n" + "="*60)
    print("‚úÖ FINE-TUNING TERMIN√â !")
    print("="*60)
    print(f"\nüì¶ Mod√®le sauvegard√© dans : {model_path}")
    print(f"üìä F1-Score : {scores['ents_f']:.2%}")
    
    if use_v2:
        print("\nüéØ Dataset V2 utilis√© - Qualit√© optimis√©e !")
        print("   ‚úÖ Pas de faux positifs sur titres de section")
        print("   ‚úÖ Pas de confusion avec les langues")
    
    print("\nProchaine √©tape : Int√©grer ce mod√®le dans le projet")
    print("\n" + "="*60 + "\n")