"""
MODULE 2 : G√©n√©rateur de Questions Intelligent
G√©n√©ration automatique de questions d'entretien avec NLP
Utilise : T5, Question Generation, Named Entity Recognition
"""

from transformers import (
    T5ForConditionalGeneration, 
    T5Tokenizer,
    pipeline
)
import spacy
from typing import List, Dict
import torch

class QuestionGenerator:
    """
    G√©n√®re automatiquement des questions d'entretien pertinentes
    Approche 100% NLP professionnelle
    """
    
    def __init__(self, use_gpu: bool = False):
        """
        Initialise le g√©n√©rateur avec les mod√®les NLP
        
        Args:
            use_gpu: Utiliser GPU si disponible (plus rapide)
        """
        print("üì• Chargement des mod√®les de g√©n√©ration de questions...")
        
        self.device = "cuda" if use_gpu and torch.cuda.is_available() else "cpu"
        print(f"üñ•Ô∏è  Device: {self.device}")
        
        # Mod√®le spaCy pour l'analyse
        self.nlp = spacy.load("fr_core_news_md")
        
        # Option 1 : Mod√®le T5 pour Question Generation (multilingue)
        # C'est un mod√®le gratuit et open source
        self.qg_model_name = "doc2query/msmarco-french-mt5-base-v1"
        
        try:
            self.qg_tokenizer = T5Tokenizer.from_pretrained(self.qg_model_name)
            self.qg_model = T5ForConditionalGeneration.from_pretrained(
                self.qg_model_name
            ).to(self.device)
            print("‚úÖ Mod√®le T5 Question Generation charg√©")
        except Exception as e:
            print(f"‚ö†Ô∏è  Erreur chargement T5, utilisation du mod√®le de base : {e}")
            # Fallback vers un mod√®le plus simple
            self.qg_model = None
        
        # Pipeline de g√©n√©ration de texte (backup)
        try:
            self.text_generator = pipeline(
                "text2text-generation",
                model="google/flan-t5-base",
                device=0 if self.device == "cuda" else -1
            )
            print("‚úÖ Pipeline de g√©n√©ration charg√©")
        except:
            self.text_generator = None
            print("‚ö†Ô∏è  Pipeline non disponible, utilisation des templates")
        
        # Templates de questions (backup professionnel)
        self.question_templates = self._load_question_templates()
        
        print("‚úÖ G√©n√©rateur de questions pr√™t")
    
    def generate_questions(
        self, 
        job_description: str,
        required_skills: List[str],
        difficulty: str = "medium",
        num_questions: int = 5
    ) -> List[Dict]:
        """
        FONCTION PRINCIPALE : G√©n√®re des questions personnalis√©es
        
        Args:
            job_description: Description compl√®te du poste
            required_skills: ["Python", "Django", "PostgreSQL"]
            difficulty: "easy", "medium", "hard"
            num_questions: Nombre de questions √† g√©n√©rer
        
        Returns:
            List[Dict]: [
                {
                    'question': "Comment optimiseriez-vous...",
                    'category': "technical",
                    'skill': "Python",
                    'difficulty': "medium",
                    'expected_keywords': ["performance", "cache", "algorithme"]
                },
                ...
            ]
        """
        questions = []
        
        # Analyser la description du poste avec spaCy
        doc = self.nlp(job_description)
        
        # Extraire les entit√©s et concepts cl√©s
        key_concepts = self._extract_key_concepts(doc)
        
        # G√©n√©rer des questions pour chaque comp√©tence
        for skill in required_skills:
            # G√©n√©rer des questions sp√©cifiques √† la comp√©tence
            skill_questions = self._generate_skill_questions(
                skill=skill,
                context=job_description,
                key_concepts=key_concepts,
                difficulty=difficulty,
                num=num_questions // len(required_skills)
            )
            questions.extend(skill_questions)
        
        # Ajouter des questions comportementales
        behavioral_questions = self._generate_behavioral_questions(
            job_description=job_description,
            num=2
        )
        questions.extend(behavioral_questions)
        
        return questions[:num_questions]
    
    def _extract_key_concepts(self, doc) -> List[str]:
        """
        Extrait les concepts cl√©s d'une description de poste
        Utilise NER (Named Entity Recognition) et patterns
        
        Args:
            doc: Document spaCy
        
        Returns:
            List[str]: Concepts cl√©s extraits
        """
        concepts = []
        
        # Extraire les entit√©s nomm√©es
        for ent in doc.ents:
            if ent.label_ in ["ORG", "PRODUCT", "TECH"]:
                concepts.append(ent.text)
        
        # Extraire les noms et verbes importants
        for token in doc:
            if token.pos_ in ["NOUN", "VERB"] and not token.is_stop:
                if len(token.text) > 3:  # Mots significatifs
                    concepts.append(token.lemma_)
        
        # D√©dupliquer et garder les plus fr√©quents
        concepts = list(set(concepts))
        
        return concepts[:10]  # Top 10 concepts
    
    def _generate_skill_questions(
        self,
        skill: str,
        context: str,
        key_concepts: List[str],
        difficulty: str,
        num: int
    ) -> List[Dict]:
        """
        G√©n√®re des questions pour une comp√©tence sp√©cifique
        
        Args:
            skill: "Python", "Django", etc.
            context: Description du poste
            key_concepts: Concepts cl√©s extraits
            difficulty: "easy", "medium", "hard"
            num: Nombre de questions
        
        Returns:
            List[Dict]: Questions g√©n√©r√©es
        """
        questions = []
        
        # Strat√©gie 1 : Utiliser T5 si disponible
        if self.qg_model is not None:
            generated = self._generate_with_t5(skill, context, difficulty, num)
            questions.extend(generated)
        
        # Strat√©gie 2 : Utiliser le pipeline si T5 √©choue
        if len(questions) < num and self.text_generator is not None:
            generated = self._generate_with_pipeline(skill, context, difficulty, num)
            questions.extend(generated)
        
        # Strat√©gie 3 : Templates intelligents (toujours disponible)
        if len(questions) < num:
            generated = self._generate_with_templates(
                skill, 
                key_concepts, 
                difficulty, 
                num - len(questions)
            )
            questions.extend(generated)
        
        return questions[:num]
    
    def _generate_with_t5(
        self, 
        skill: str, 
        context: str, 
        difficulty: str, 
        num: int
    ) -> List[Dict]:
        """
        G√©n√©ration avec mod√®le T5 (Question Generation)
        
        Args:
            skill: Comp√©tence cibl√©e
            context: Contexte du poste
            difficulty: Niveau de difficult√©
            num: Nombre de questions
        
        Returns:
            List[Dict]: Questions g√©n√©r√©es
        """
        questions = []
        
        try:
            # Construire le prompt pour T5
            # T5 est entra√Æn√© sur du Question Generation
            prompt = f"G√©n√®re une question d'entretien technique sur {skill}. Contexte : {context[:200]}"
            
            # Encoder le prompt
            inputs = self.qg_tokenizer.encode(
                prompt, 
                return_tensors="pt",
                max_length=512,
                truncation=True
            ).to(self.device)
            
            # G√©n√©rer plusieurs questions
            outputs = self.qg_model.generate(
                inputs,
                max_length=100,
                num_return_sequences=num,
                num_beams=5,
                temperature=0.7,
                do_sample=True
            )
            
            # D√©coder les questions
            for output in outputs:
                question_text = self.qg_tokenizer.decode(
                    output, 
                    skip_special_tokens=True
                )
                
                questions.append({
                    'question': question_text,
                    'category': 'technical',
                    'skill': skill,
                    'difficulty': difficulty,
                    'expected_keywords': self._extract_keywords(question_text),
                    'generation_method': 't5'
                })
        
        except Exception as e:
            print(f"‚ö†Ô∏è  Erreur g√©n√©ration T5 : {e}")
        
        return questions
    
    def _generate_with_pipeline(
        self, 
        skill: str, 
        context: str, 
        difficulty: str, 
        num: int
    ) -> List[Dict]:
        """
        G√©n√©ration avec pipeline text2text
        
        Args:
            skill: Comp√©tence
            context: Contexte
            difficulty: Difficult√©
            num: Nombre
        
        Returns:
            List[Dict]: Questions g√©n√©r√©es
        """
        questions = []
        
        try:
            # Prompts selon le niveau de difficult√©
            difficulty_prompts = {
                "easy": f"Pose une question simple sur les bases de {skill}",
                "medium": f"Pose une question de niveau interm√©diaire sur {skill} dans le contexte : {context[:100]}",
                "hard": f"Pose une question avanc√©e et technique sur {skill} n√©cessitant une expertise approfondie"
            }
            
            prompt = difficulty_prompts.get(difficulty, difficulty_prompts["medium"])
            
            # G√©n√©rer avec le pipeline
            results = self.text_generator(
                prompt,
                max_length=100,
                num_return_sequences=num,
                temperature=0.8
            )
            
            for result in results:
                question_text = result['generated_text']
                
                questions.append({
                    'question': question_text,
                    'category': 'technical',
                    'skill': skill,
                    'difficulty': difficulty,
                    'expected_keywords': self._extract_keywords(question_text),
                    'generation_method': 'pipeline'
                })
        
        except Exception as e:
            print(f"‚ö†Ô∏è  Erreur g√©n√©ration pipeline : {e}")
        
        return questions
    
    def _generate_with_templates(
        self, 
        skill: str, 
        key_concepts: List[str], 
        difficulty: str, 
        num: int
    ) -> List[Dict]:
        """
        G√©n√©ration avec templates intelligents (backup)
        Templates structur√©s mais enrichis par NLP
        
        Args:
            skill: Comp√©tence
            key_concepts: Concepts cl√©s du poste
            difficulty: Difficult√©
            num: Nombre
        
        Returns:
            List[Dict]: Questions g√©n√©r√©es
        """
        questions = []
        
        # Templates par niveau de difficult√©
        templates = self.question_templates.get(difficulty, {}).get(skill.lower(), [])
        
        # Si pas de templates sp√©cifiques, utiliser les g√©n√©riques
        if not templates:
            templates = self.question_templates.get(difficulty, {}).get('generic', [])
        
        # G√©n√©rer des questions en remplissant les templates
        for i, template in enumerate(templates[:num]):
            # Enrichir le template avec les concepts cl√©s
            if key_concepts and "{concept}" in template:
                concept = key_concepts[i % len(key_concepts)]
                question_text = template.format(skill=skill, concept=concept)
            else:
                question_text = template.format(skill=skill)
            
            questions.append({
                'question': question_text,
                'category': 'technical',
                'skill': skill,
                'difficulty': difficulty,
                'expected_keywords': self._extract_keywords(question_text),
                'generation_method': 'template'
            })
        
        return questions
    
    def _generate_behavioral_questions(
        self, 
        job_description: str, 
        num: int = 2
    ) -> List[Dict]:
        """
        G√©n√®re des questions comportementales
        Bas√©es sur le STAR method (Situation, Task, Action, Result)
        
        Args:
            job_description: Description du poste
            num: Nombre de questions
        
        Returns:
            List[Dict]: Questions comportementales
        """
        questions = []
        
        # Analyser la description pour extraire les soft skills
        doc = self.nlp(job_description)
        
        # Soft skills courantes
        soft_skills = {
            'travail en √©quipe': "Parlez-moi d'une situation o√π vous avez d√ª collaborer avec une √©quipe difficile. Comment avez-vous g√©r√© cela ?",
            'leadership': "D√©crivez une situation o√π vous avez d√ª prendre le leadership sur un projet. Quels ont √©t√© les r√©sultats ?",
            'gestion du stress': "Racontez-moi comment vous avez g√©r√© une deadline serr√©e ou une situation de pression.",
            'r√©solution de probl√®mes': "Donnez-moi un exemple d'un probl√®me complexe que vous avez r√©solu. Quelle a √©t√© votre approche ?",
            'adaptabilit√©': "Parlez-moi d'une fois o√π vous avez d√ª vous adapter rapidement √† un changement majeur.",
            'communication': "D√©crivez une situation o√π vous avez d√ª expliquer un concept technique complexe √† un non-technicien."
        }
        
        # D√©tecter les soft skills mentionn√©es dans la description
        detected_skills = []
        for skill_key in soft_skills.keys():
            if skill_key in job_description.lower():
                detected_skills.append(skill_key)
        
        # Si aucune d√©tect√©e, utiliser les plus courantes
        if not detected_skills:
            detected_skills = ['travail en √©quipe', 'r√©solution de probl√®mes']
        
        # G√©n√©rer les questions
        for skill in detected_skills[:num]:
            questions.append({
                'question': soft_skills[skill],
                'category': 'behavioral',
                'skill': skill,
                'difficulty': 'medium',
                'expected_keywords': ['situation', 'action', 'r√©sultat', '√©quipe', 'projet'],
                'generation_method': 'behavioral'
            })
        
        return questions
    
    def _extract_keywords(self, question: str) -> List[str]:
        """
        Extrait les mots-cl√©s importants d'une question
        Utilis√© pour √©valuer les r√©ponses
        
        Args:
            question: Texte de la question
        
        Returns:
            List[str]: Mots-cl√©s extraits
        """
        doc = self.nlp(question)
        
        keywords = []
        for token in doc:
            # Garder les noms, verbes et adjectifs importants
            if token.pos_ in ["NOUN", "VERB", "ADJ"] and not token.is_stop:
                if len(token.text) > 3:
                    keywords.append(token.lemma_.lower())
        
        return list(set(keywords))[:5]  # Top 5 keywords
    
    def _load_question_templates(self) -> Dict:
        """
        Charge les templates de questions (backup)
        Structure : {difficulty: {skill: [templates]}}
        
        Returns:
            Dict: Templates organis√©s
        """
        return {
            "easy": {
                "python": [
                    "Quelle est la diff√©rence entre une liste et un tuple en {skill} ?",
                    "Expliquez ce qu'est un dictionnaire en {skill}.",
                    "Comment cr√©er une fonction simple en {skill} ?"
                ],
                "javascript": [
                    "Quelle est la diff√©rence entre var, let et const en {skill} ?",
                    "Expliquez ce qu'est une fonction fl√©ch√©e en {skill}.",
                    "Comment d√©clarer un tableau en {skill} ?"
                ],
                "generic": [
                    "Expliquez les bases de {skill}.",
                    "Quelle est votre exp√©rience avec {skill} ?",
                    "Quels sont les concepts fondamentaux de {skill} ?"
                ]
            },
            "medium": {
                "python": [
                    "Comment g√©rez-vous les exceptions en {skill} ? Donnez un exemple.",
                    "Expliquez le concept de d√©corateur en {skill} avec {concept}.",
                    "Comment optimiseriez-vous une boucle en {skill} traitant {concept} ?"
                ],
                "javascript": [
                    "Expliquez le concept de closure en {skill}.",
                    "Comment fonctionne l'asynchronisme en {skill} avec {concept} ?",
                    "Quelle est la diff√©rence entre Promise et async/await en {skill} ?"
                ],
                "generic": [
                    "Comment utiliseriez-vous {skill} pour r√©soudre {concept} ?",
                    "D√©crivez un projet o√π vous avez utilis√© {skill}.",
                    "Quelles sont les meilleures pratiques en {skill} ?"
                ]
            },
            "hard": {
                "python": [
                    "Expliquez le Global Interpreter Lock (GIL) en {skill} et ses implications.",
                    "Comment impl√©menteriez-vous un syst√®me de cache avec {skill} pour {concept} ?",
                    "D√©crivez l'architecture d'une application {skill} scalable g√©rant {concept}."
                ],
                "javascript": [
                    "Expliquez le m√©canisme de l'event loop en {skill}.",
                    "Comment optimiseriez-vous les performances d'une application {skill} avec {concept} ?",
                    "Impl√©mentez un syst√®me de gestion d'√©tat complexe en {skill}."
                ],
                "generic": [
                    "Concevez une architecture compl√®te utilisant {skill} pour {concept}.",
                    "Quels sont les d√©fis de scalabilit√© avec {skill} ?",
                    "Comment d√©buguer un probl√®me de performance complexe en {skill} ?"
                ]
            }
        }
    
    def adapt_difficulty(self, current_score: float, difficulty: str) -> str:
        """
        Adapte la difficult√© des questions selon le score actuel
        
        Args:
            current_score: Score moyen actuel (0-100)
            difficulty: Difficult√© actuelle
        
        Returns:
            str: Nouvelle difficult√© sugg√©r√©e
        """
        if current_score >= 85:
            return "hard"
        elif current_score >= 70:
            return "medium" if difficulty != "hard" else "hard"
        elif current_score >= 50:
            return "medium"
        else:
            return "easy"


# ============ EXEMPLE D'UTILISATION ============

if __name__ == "__main__":
    # Test du g√©n√©rateur
    generator = QuestionGenerator(use_gpu=False)
    
    # Description de poste exemple
    job_desc = """
    Nous recherchons un d√©veloppeur Python senior avec une expertise en Django.
    Le candidat devra concevoir et maintenir des APIs RESTful, optimiser les 
    performances des bases de donn√©es PostgreSQL, et travailler en √©quipe agile.
    """
    
    # G√©n√©rer des questions
    questions = generator.generate_questions(
        job_description=job_desc,
        required_skills=["Python", "Django", "PostgreSQL"],
        difficulty="medium",
        num_questions=5
    )
    
    # Afficher les r√©sultats
    for i, q in enumerate(questions, 1):
        print(f"\n{i}. {q['question']}")
        print(f"   Cat√©gorie: {q['category']}")
        print(f"   Comp√©tence: {q['skill']}")
        print(f"   Difficult√©: {q['difficulty']}")
        print(f"   M√©thode: {q['generation_method']}")
        print(f"   Mots-cl√©s attendus: {', '.join(q['expected_keywords'])}")